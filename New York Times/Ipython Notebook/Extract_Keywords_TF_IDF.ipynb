{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import operator\n",
    "import unicodedata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_num = 100\n",
    "data = pd.read_csv('Immigration_news_data_content_bin' + str(bin_num) + '(2).csv')\n",
    "year = data['date'].tolist()\n",
    "content = data['content'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are around 100 bins here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            content  \\\n",
      "0           0  israeli paper says jews released ceausescu pai...   \n",
      "1           0  religion notes lead giving gospels away weeks ...   \n",
      "2           0  florida center holding aliens inquiry lead ami...   \n",
      "3           0  brooklyn landlord keep racial mix looks soviet...   \n",
      "4           0  israeli committee backs settlement east jerusa...   \n",
      "\n",
      "                    date  \n",
      "0  1990-01-01,1990-03-09  \n",
      "1  1990-03-10,1990-05-16  \n",
      "2  1990-05-16,1990-07-24  \n",
      "3  1990-07-24,1990-10-16  \n",
      "4  1990-10-16,1991-01-06  \n"
     ]
    }
   ],
   "source": [
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "vectorizer = TfidfVectorizer(max_df=.7, max_features=20000,\n",
    "                             min_df=.02, stop_words='english',\n",
    "                            use_idf=True, ngram_range=(1,3))\n",
    "tfidf_matrix = vectorizer.fit_transform(content)\n",
    "idf = vectorizer.idf_\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "words = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "for key, val in words.iteritems():\n",
    "    word_dict[key]=val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF-IDF from Sklearn to analyze the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20000)\n"
     ]
    }
   ],
   "source": [
    "print tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 is the row number, the number of bins. 200000 is the total number of featured words here, the column number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print len(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the words by their idf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyword_list = sorted(word_dict.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for l in keyword_list:\n",
    "    print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense = tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the sklearn sparse matrix into a dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for i in range(len(content)):\n",
    "    cluster = dense[i].tolist()[0]\n",
    "    clusters.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_keywords(data):\n",
    "    phrase_scores = []\n",
    "    for pair in zip(range(0, len(data)), data):\n",
    "        if pair[1] > 0:\n",
    "            phrase_scores.append(pair)\n",
    "    \n",
    "    sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "    keywords = []\n",
    "    keywords_pair = []\n",
    "    for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores]:\n",
    "        phrase = unicodedata.normalize('NFKD', phrase).encode('ascii','ignore')\n",
    "        keywords.append(phrase)\n",
    "        keywords_pair.append((phrase, score))\n",
    "    return keywords, keywords_pair\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the keywords for every row, the bin from the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyword_list = []\n",
    "keywords_pair_list = []\n",
    "for cluster in clusters:\n",
    "    keywords, keywords_pair = extract_keywords(cluster)\n",
    "    keyword_list.append(keywords[:10])\n",
    "    keywords_pair_list.append(keywords_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = { 'content': content, \"date\": year, \"keywords\": keyword_list, \"keywords pair\": keywords_pair_list }\n",
    "\n",
    "frame = pd.DataFrame(new_data, columns = ['content', \"date\", \"keywords\", \"keywords pair\"])\n",
    "frame.to_csv('Immigration_news_data_content_bin' + str(bin_num) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            content  \\\n",
      "0           0  israeli paper says jews released ceausescu pai...   \n",
      "1           1  religion notes lead giving gospels away weeks ...   \n",
      "2           2  florida center holding aliens inquiry lead ami...   \n",
      "3           3  brooklyn landlord keep racial mix looks soviet...   \n",
      "4           4  israeli committee backs settlement east jerusa...   \n",
      "\n",
      "                    date                                           keywords  \\\n",
      "0  1990-01-01,1990-03-09  ['immigration emigration', 'emigration', 'lead...   \n",
      "1  1990-03-10,1990-05-16  ['immigration emigration', 'emigration', 'sovi...   \n",
      "2  1990-05-16,1990-07-24  ['immigration emigration', 'emigration', 'gorb...   \n",
      "3  1990-07-24,1990-10-16  ['immigration emigration', 'emigration', 'elli...   \n",
      "4  1990-10-16,1991-01-06  ['immigration emigration', 'emigration', 'weir...   \n",
      "\n",
      "                                       keywords pair  \n",
      "0  [('immigration emigration', 0.4133313415845711...  \n",
      "1  [('immigration emigration', 0.4247530367441615...  \n",
      "2  [('immigration emigration', 0.375187169460169)...  \n",
      "3  [('immigration emigration', 0.5196340658840813...  \n",
      "4  [('immigration emigration', 0.3739294900384202...  \n"
     ]
    }
   ],
   "source": [
    "frame = pd.read_csv('Immigration_news_data_content_bin' + str(bin_num) + '.csv')\n",
    "print frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyson                0.356025083595\n",
      "foods                0.180862562832\n",
      "tyson foods          0.180862562832\n",
      "hunger               0.157924144013\n",
      "hunger strike        0.15071880236\n",
      "guilty               0.129637653581\n",
      "tuition              0.129637653581\n",
      "kennedy              0.126339315211\n",
      "middle eastern       0.126339315211\n",
      "inmate               0.120575041888\n",
      "singapore            0.117234004377\n",
      "australia            0.114213758153\n",
      "pilot                0.114213758153\n",
      "trial                0.112352633104\n",
      "government said      0.10551060394\n",
      "taiwan               0.10551060394\n",
      "hong                 0.103710122865\n",
      "hong kong            0.103710122865\n",
      "kong                 0.103710122865\n",
      "strike               0.103710122865\n"
     ]
    }
   ],
   "source": [
    "# sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "# for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:20]:\n",
    "#    print('{0: <20} {1}'.format(phrase, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
